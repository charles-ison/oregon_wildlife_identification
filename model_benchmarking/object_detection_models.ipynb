{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9KL9nUitbYwh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ECpQROeamJfA"
      },
      "outputs": [],
      "source": [
        "class image_data_set(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        return {'data': self.data[index], 'label': self.labels[index]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "qyIy4drE2BUt"
      },
      "outputs": [],
      "source": [
        "def print_data_analysis(present_lighting_sufficient_data, \n",
        "                        present_lighting_insufficient_data, \n",
        "                        not_present_lighting_sufficient_data, \n",
        "                        not_present_lighting_insufficient_data):\n",
        "  \n",
        "    subplot = plt.subplot()\n",
        "    data_lengthes = np.array([\n",
        "        [len(present_lighting_sufficient_data), len(present_lighting_insufficient_data)], \n",
        "        [len(not_present_lighting_sufficient_data), len(not_present_lighting_insufficient_data)]\n",
        "    ])\n",
        "    sns.heatmap(data_lengthes, annot=True, fmt='g', cmap='Blues')\n",
        "    subplot.xaxis.set_ticklabels(['Lighting Sufficient', 'Lighting Not Sufficient'])\n",
        "    subplot.yaxis.set_ticklabels(['Wildlife Present', 'No Wildlife Present'])\n",
        "    plt.show()\n",
        "\n",
        "def get_image_tensor(file_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    \n",
        "    image = Image.open(file_path)\n",
        "    return transform(image)\n",
        "\n",
        "def get_data_and_labels(directory_path, label):\n",
        "    image_tensors, labels = [], []\n",
        "    for file in os.listdir(directory_path):\n",
        "        if file.endswith(\".JPG\"):\n",
        "            file_path = directory_path + file\n",
        "            image_tensor = get_image_tensor(file_path)\n",
        "\n",
        "            image_tensors.append(image_tensor)\n",
        "            labels.append(label)\n",
        "            \n",
        "    return image_tensors, labels\n",
        "\n",
        "def get_data_for_label(file_pathes, label): \n",
        "\n",
        "  all_data, all_labels = [], []\n",
        "  for file_path in file_pathes:\n",
        "      data, labels = get_data_and_labels(file_path, label)\n",
        "      all_data.extend(data)\n",
        "      all_labels.extend(labels)\n",
        "\n",
        "  return all_data, all_labels\n",
        "    \n",
        "def get_data_sets(present_file_pathes_lighting_sufficient, \n",
        "                  present_file_pathes_lighting_insufficient,\n",
        "                  not_present_file_pathes_lighting_sufficient,\n",
        "                  not_present_file_pathes_lighting_insufficient): \n",
        "\n",
        "    present_ls_data, present_ls_labels = get_data_for_label(present_file_pathes_lighting_sufficient, 1)\n",
        "    present_lis_data, present_lis_labels = get_data_for_label(present_file_pathes_lighting_insufficient, 1)\n",
        "    not_present_ls_data, not_present_ls_labels = get_data_for_label(not_present_file_pathes_lighting_sufficient, 0)\n",
        "    not_present_lis_data, not_present_lis_labels = get_data_for_label(not_present_file_pathes_lighting_insufficient, 0)\n",
        "\n",
        "    print_data_analysis(present_ls_data, present_lis_data, not_present_ls_data, not_present_lis_data)\n",
        "    \n",
        "    ls_data = present_ls_data + not_present_ls_data\n",
        "    ls_labels = present_ls_labels + not_present_ls_labels\n",
        "\n",
        "    lis_data = present_lis_data + not_present_lis_data\n",
        "    lis_labels = present_lis_labels + not_present_lis_labels\n",
        "    \n",
        "    ls_training_data, ls_testing_data, ls_training_labels, ls_testing_labels = train_test_split(ls_data, ls_labels)\n",
        "    lis_training_data, lis_testing_data, lis_training_labels, lis_testing_labels = train_test_split(lis_data, lis_labels)\n",
        "\n",
        "    training_data = ls_training_data + lis_training_data\n",
        "    testing_data = ls_testing_data + lis_testing_data\n",
        "    training_labels = ls_training_labels + lis_training_labels\n",
        "    testing_labels = ls_testing_labels + lis_testing_labels\n",
        "    \n",
        "    print(\"\\nNumber of training photos: \" + str(len(training_data)))\n",
        "    print(\"Number of testing photos: \" + str(len(testing_data)))\n",
        "    print(\"Number of lighting sufficient testing photos: \" + str(len(ls_testing_data)))\n",
        "    print(\"Number of lighting insufficient testing photos: \" + str(len(lis_testing_data)))\n",
        "    \n",
        "    training_data_set = image_data_set(training_data, training_labels)\n",
        "    testing_data_set = image_data_set(testing_data, testing_labels)\n",
        "    ls_testing_data_set = image_data_set(ls_testing_data, ls_testing_labels)\n",
        "    lis_testing_data_set = image_data_set(lis_testing_data, lis_testing_labels)\n",
        "    \n",
        "    return training_data_set, testing_data_set, ls_testing_data_set, lis_testing_data_set\n",
        "\n",
        "def get_loaders(training_data_set, testing_data_set, ls_testing_data_set, lis_testing_data_set, batch_size):\n",
        "    training_loader = torch.utils.data.DataLoader(dataset = training_data_set,\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  shuffle = True)\n",
        "\n",
        "    testing_loader = torch.utils.data.DataLoader(dataset = testing_data_set,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 shuffle = True)\n",
        "    \n",
        "    ls_testing_loader = torch.utils.data.DataLoader(dataset = ls_testing_data_set,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 shuffle = True)\n",
        "    \n",
        "    lis_testing_loader = torch.utils.data.DataLoader(dataset = lis_testing_data_set,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 shuffle = True)\n",
        "    \n",
        "    return training_loader, testing_loader, ls_testing_loader, lis_testing_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wpeG79qU2Tdh"
      },
      "outputs": [],
      "source": [
        "def print_image(image_tensor, prediction):\n",
        "    if(prediction == 1):\n",
        "        prediction_string = \"Wildlife Present\"\n",
        "    else:\n",
        "        prediction_string = \"No Wildlife Present\"\n",
        "\n",
        "    #Alternative normalized RGB visualization: plt.imshow(image_tensor.cpu().permute(1, 2, 0).numpy())\n",
        "    plt.imshow(image_tensor[0].cpu(), cmap=\"gray\")\n",
        "    plt.title(\"Incorrectly Predicted \" + prediction_string) \n",
        "    plt.show()\n",
        "\n",
        "def print_testing_analysis(all_labels, all_predictions, title):\n",
        "    subplot = plt.subplot()\n",
        "\n",
        "    cf_matrix = confusion_matrix(all_labels, all_predictions, labels=[1, 0])\n",
        "    sns.heatmap(cf_matrix, annot=True, fmt='g', cmap='Blues')\n",
        "\n",
        "    subplot.set_xlabel('Predictions')\n",
        "    subplot.set_ylabel('Labels')\n",
        "    subplot.set_title(title + ' Testing Confusion Matrix')\n",
        "    subplot.xaxis.set_ticklabels(['Wildlife Present', 'No Wildlife Present'])\n",
        "    subplot.yaxis.set_ticklabels(['Wildlife Present', 'No Wildlife Present'])\n",
        "    plt.show()\n",
        "\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    print(title + \" Accuracy: \" + str(accuracy))\n",
        "\n",
        "    precision, recall, f_score, support = precision_recall_fscore_support(all_labels, all_predictions, average='binary')\n",
        "    print(title + \" Precision: \" + str(precision))\n",
        "    print(title + \" Recall: \" + str(recall))\n",
        "    print(title + \" F-Score: \" + str(f_score))\n",
        "\n",
        "def train(model, training_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(training_loader):\n",
        "        data, labels = data['data'].to(device), data['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    loss = running_loss/len(training_loader.dataset)\n",
        "    accuracy = num_correct/len(training_loader.dataset)\n",
        "    return loss, accuracy\n",
        "\n",
        "def test(model, testing_loader, criterion, print_incorrect_images):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    num_correct = 0\n",
        "    all_labels, all_predictions = [], []\n",
        "\n",
        "    for i, data in enumerate(testing_loader):\n",
        "        data, labels = data['data'].to(device), data['label'].to(device)\n",
        "        output = model(data)\n",
        "\n",
        "        print(\"labels: \" + str(labels))\n",
        "        print(\"output: \" + str(output))\n",
        "\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        for index, prediction in enumerate(predictions):\n",
        "            if(prediction == labels[index]):\n",
        "                num_correct += 1\n",
        "            elif(print_incorrect_images):\n",
        "                print_image(data[index], prediction)\n",
        "\n",
        "        all_labels.extend(labels.cpu())\n",
        "        all_predictions.extend(predictions.cpu())\n",
        "    \n",
        "    loss = running_loss/len(testing_loader.dataset)\n",
        "    accuracy = num_correct/len(testing_loader.dataset)\n",
        "    return loss, accuracy, all_labels, all_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ZBTEy1kg3pem"
      },
      "outputs": [],
      "source": [
        "def train_and_test(model, training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    \n",
        "    for epoch in range(5):\n",
        "        print(\"epoch: \" + str(epoch))\n",
        "        \n",
        "        training_loss, training_accuracy = train(model, training_loader, criterion, optimizer)\n",
        "        print(\"training loss: \" + str(training_loss) + \" and training accuracy: \" + str(training_accuracy))\n",
        "        \n",
        "        testing_loss, testing_accuracy, _, _ = test(model, testing_loader, criterion, False)\n",
        "        print(\"testing loss: \" + str(testing_loss) + \" and testing accuracy: \" + str(testing_accuracy))\n",
        "\n",
        "    testing_loss, testing_accuracy, labels, predictions = test(model, testing_loader, criterion, True)\n",
        "    print_testing_analysis(labels, predictions, \"Overall\")\n",
        "\n",
        "    testing_loss, testing_accuracy, labels, predictions = test(model, ls_testing_loader, criterion, False)\n",
        "    print_testing_analysis(labels, predictions, \"Lighting Sufficient\")\n",
        "\n",
        "    testing_loss, testing_accuracy, labels, predictions = test(model, lis_testing_loader, criterion, False)\n",
        "    print_testing_analysis(labels, predictions, \"Lighting Insufficient\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "678WuU6g3tuV"
      },
      "outputs": [],
      "source": [
        "def train_and_test_SSD(training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing SSD\")\n",
        "    ssd300_vgg16 = models.detection.ssd300_vgg16(weights=models.detection.SSD300_VGG16_Weights.COCO_V1)\n",
        "    #train_and_test(ssd300_vgg16, training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device)\n",
        "\n",
        "    ssd300_vgg16.to(device)\n",
        "    testing_loss, testing_accuracy, _, _ = test(ssd300_vgg16, testing_loader, nn.CrossEntropyLoss(), False)\n",
        "    \n",
        "def train_and_test_Faster_RCNN(training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing Faster R-CNN\")\n",
        "    faster_rcnn = models.detection.fasterrcnn_resnet50_fpn_v2(weights=models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT)\n",
        "    num_classes = 2 \n",
        "    in_features = faster_rcnn.roi_heads.box_predictor.cls_score.in_features\n",
        "    faster_rcnn.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
        "\n",
        "    #train_and_test(faster_rcnn, training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device)\n",
        "    faster_rcnn.to(device)\n",
        "    testing_loss, testing_accuracy, _, _ = test(faster_rcnn, testing_loader, nn.CrossEntropyLoss(), False)\n",
        "    \n",
        "def train_and_test_YOLO(training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing YOLO\")\n",
        "    yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "    #train_and_test(yolo, training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAAF1fMaol0q"
      },
      "source": [
        "#Orchestration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89jqZ2L-3yeo",
        "outputId": "7d2453b4-108c-4051-c2bc-813dc9f314ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Use this to connect to Google Drive in Google Colab\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Use this to unzip file in Google Colab\n",
        "!unzip -qq drive/MyDrive/manually_labeled_wildlife_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "rUjoI3B4W2ma",
        "outputId": "435668a9-6ee0-442b-e5d5-58e650fe8ef8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number of training photos: 2996\n",
            "Number of testing photos: 999\n",
            "Number of lighting sufficient testing photos: 891\n",
            "Number of lighting insufficient testing photos: 108\n"
          ]
        }
      ],
      "source": [
        "present_file_pathes_ls = [\n",
        "  \"manually_labeled_wildlife_data/MP152_ODOT009_REPELCAM/present/lighting_sufficient/\",\n",
        "  \"manually_labeled_wildlife_data/MP152_ODOT003_EASTFACE/present/lighting_sufficient/\"\n",
        "]\n",
        "\n",
        "present_file_pathes_lis = [\n",
        "  \"manually_labeled_wildlife_data/MP152_ODOT009_REPELCAM/present/lighting_insufficient/\",\n",
        "  \"manually_labeled_wildlife_data/MP152_ODOT003_EASTFACE/present/lighting_insufficient/\"\n",
        "]\n",
        "\n",
        "not_present_file_pathes_ls = [\n",
        "  \"manually_labeled_wildlife_data/MP152_ODOT009_REPELCAM/not_present/lighting_sufficient/\",\n",
        "  \"manually_labeled_wildlife_data/MP152_ODOT003_EASTFACE/not_present/lighting_sufficient/\",\n",
        "]\n",
        "\n",
        "not_present_file_pathes_lis = [\n",
        "  \"manually_labeled_wildlife_data/MP152_ODOT009_REPELCAM/not_present/lighting_insufficient/\",\n",
        "  \"manually_labeled_wildlife_data/MP152_ODOT003_EASTFACE/not_present/lighting_insufficient/\",\n",
        "]\n",
        "\n",
        "num_classes = 2\n",
        "batch_size = 2\n",
        "\n",
        "training_data_set, testing_data_set, ls_testing_data_set, lis_testing_data_set = get_data_sets(\n",
        "    present_file_pathes_ls, \n",
        "    present_file_pathes_lis,\n",
        "    not_present_file_pathes_ls,\n",
        "    not_present_file_pathes_lis\n",
        ")\n",
        "training_loader, testing_loader, ls_testing_loader, lis_testing_loader = get_loaders(\n",
        "    training_data_set, \n",
        "    testing_data_set, \n",
        "    ls_testing_data_set, \n",
        "    lis_testing_data_set, \n",
        "    batch_size\n",
        ")\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "U4sGC2wTCfZW",
        "outputId": "ef1bb6d8-bb1a-44d5-9bdd-2143e65fabf4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and Testing Faster R-CNN\n",
            "labels: tensor([0, 1], device='cuda:0')\n",
            "output: [{'boxes': tensor([[9.8525e+01, 0.0000e+00, 1.0695e+02, 5.3328e+00],\n",
            "        [5.0470e+01, 0.0000e+00, 5.8287e+01, 6.1386e+00],\n",
            "        [7.6426e+01, 1.2248e+02, 8.4075e+01, 1.4105e+02],\n",
            "        [5.5864e+00, 1.2182e+02, 1.9954e+01, 1.4067e+02],\n",
            "        [5.2016e+01, 0.0000e+00, 5.6147e+01, 5.5679e+00],\n",
            "        [1.2374e+00, 7.8333e+00, 3.2937e+01, 4.2250e+01],\n",
            "        [1.6593e+01, 1.2048e+02, 2.8145e+01, 1.4529e+02],\n",
            "        [7.4189e+01, 1.1725e+02, 8.6683e+01, 1.3679e+02],\n",
            "        [1.9228e+01, 0.0000e+00, 2.8884e+01, 5.3783e+00],\n",
            "        [5.3585e+01, 1.1778e+02, 6.0655e+01, 1.3376e+02],\n",
            "        [4.3839e+01, 0.0000e+00, 5.1387e+01, 6.4520e+00],\n",
            "        [7.5069e+01, 1.1644e+02, 9.4374e+01, 1.5981e+02],\n",
            "        [4.9242e+01, 1.1797e+02, 6.2367e+01, 1.3510e+02],\n",
            "        [2.5807e+01, 1.3050e+02, 4.2822e+01, 1.4869e+02],\n",
            "        [2.0372e+01, 1.2780e+02, 3.7074e+01, 1.4756e+02],\n",
            "        [1.7224e+01, 1.1339e+02, 4.7207e+01, 1.4523e+02],\n",
            "        [4.5417e+01, 1.2631e+02, 5.9928e+01, 1.4486e+02],\n",
            "        [2.0877e+01, 1.1603e+02, 3.3315e+01, 1.4545e+02],\n",
            "        [7.9862e+00, 0.0000e+00, 1.7948e+01, 5.3065e+00],\n",
            "        [6.9648e+01, 0.0000e+00, 7.9286e+01, 5.6998e+00],\n",
            "        [2.7149e-02, 4.4477e+00, 1.7248e+01, 4.7371e+01],\n",
            "        [2.5230e+01, 1.3511e+02, 3.7509e+01, 1.4840e+02],\n",
            "        [0.0000e+00, 0.0000e+00, 5.4085e+01, 5.5836e+01],\n",
            "        [2.0539e+02, 0.0000e+00, 2.1512e+02, 5.3846e+00],\n",
            "        [5.6313e+01, 8.8217e+01, 1.5684e+02, 1.4313e+02],\n",
            "        [7.6542e+01, 1.1857e+02, 9.3923e+01, 1.4192e+02],\n",
            "        [2.3031e+01, 0.0000e+00, 3.2772e+01, 8.2490e+00],\n",
            "        [1.1440e+01, 1.2345e+02, 1.9364e+01, 1.4197e+02],\n",
            "        [0.0000e+00, 1.1325e+02, 1.2616e+01, 1.3590e+02],\n",
            "        [1.4046e+01, 0.0000e+00, 2.2442e+01, 6.3811e+00],\n",
            "        [9.8018e+00, 0.0000e+00, 1.9380e+01, 8.1926e+00],\n",
            "        [6.9639e+01, 1.1769e+02, 1.0632e+02, 1.4190e+02],\n",
            "        [2.0957e+02, 0.0000e+00, 2.1814e+02, 7.1375e+00],\n",
            "        [4.5365e+01, 1.1220e+02, 6.2982e+01, 1.4989e+02],\n",
            "        [7.4627e+01, 1.1794e+02, 8.1082e+01, 1.3796e+02],\n",
            "        [6.1958e+01, 6.3049e+01, 1.3151e+02, 8.0428e+01],\n",
            "        [0.0000e+00, 5.0831e+00, 3.6865e+01, 2.6522e+01],\n",
            "        [5.2384e-01, 0.0000e+00, 1.6325e+01, 2.1257e+02],\n",
            "        [6.2372e+01, 7.3506e+01, 7.7140e+01, 9.0517e+01],\n",
            "        [6.8962e-01, 0.0000e+00, 8.3592e+00, 6.0246e+00],\n",
            "        [1.0458e+01, 1.0135e+02, 2.4743e+01, 1.1707e+02],\n",
            "        [1.5783e+01, 0.0000e+00, 2.4913e+01, 8.3345e+00],\n",
            "        [2.1916e+01, 1.1371e+02, 6.6935e+01, 1.3581e+02],\n",
            "        [2.4085e+01, 1.2943e+02, 3.2629e+01, 1.4700e+02],\n",
            "        [2.1243e+02, 0.0000e+00, 2.2059e+02, 6.7967e+00],\n",
            "        [4.2462e+00, 0.0000e+00, 1.4087e+01, 6.4641e+00],\n",
            "        [7.2265e+00, 1.2075e+02, 1.5489e+01, 1.3809e+02],\n",
            "        [3.5244e+01, 0.0000e+00, 4.3598e+01, 6.8518e+00],\n",
            "        [3.2472e-01, 1.2301e+02, 9.6891e+00, 1.3630e+02],\n",
            "        [2.6648e-01, 1.0733e+02, 7.2074e+00, 1.8664e+02],\n",
            "        [2.2639e+01, 1.1287e+02, 2.8651e+01, 1.2871e+02],\n",
            "        [1.8926e+01, 1.0977e+02, 2.9410e+01, 1.4018e+02],\n",
            "        [4.9198e+00, 1.1196e+02, 3.0715e+01, 1.4534e+02],\n",
            "        [1.9259e+02, 7.2260e+01, 2.1129e+02, 1.0898e+02],\n",
            "        [0.0000e+00, 1.0495e+02, 2.4303e+01, 1.3636e+02],\n",
            "        [5.0768e+01, 6.1896e+01, 8.0480e+01, 9.0880e+01],\n",
            "        [1.1726e-01, 1.0573e+02, 9.5878e+00, 1.1911e+02],\n",
            "        [1.8797e+02, 0.0000e+00, 1.9730e+02, 7.5418e+00],\n",
            "        [1.8001e+01, 1.0721e+02, 3.1433e+01, 1.2493e+02],\n",
            "        [3.3090e+01, 1.1856e+02, 6.2781e+01, 1.4759e+02],\n",
            "        [6.4110e+01, 1.0370e+02, 7.8160e+01, 1.1829e+02],\n",
            "        [2.2831e+01, 1.0946e+02, 3.6193e+01, 1.2667e+02],\n",
            "        [2.4976e+01, 1.2437e+02, 4.0738e+01, 1.4354e+02],\n",
            "        [1.8398e+02, 6.6226e+01, 2.1567e+02, 9.9716e+01],\n",
            "        [3.9447e+01, 1.2441e+02, 5.5176e+01, 1.4235e+02],\n",
            "        [8.9855e+01, 1.2158e+02, 1.0376e+02, 1.4043e+02],\n",
            "        [2.3521e-01, 0.0000e+00, 6.6254e+00, 1.1557e+01],\n",
            "        [4.3786e+01, 1.1638e+02, 5.9367e+01, 1.3337e+02],\n",
            "        [0.0000e+00, 2.1934e+02, 7.8272e+00, 2.2360e+02],\n",
            "        [2.1303e+02, 7.7209e+01, 2.2317e+02, 9.1237e+01],\n",
            "        [2.7593e+01, 0.0000e+00, 3.6206e+01, 5.2906e+00],\n",
            "        [3.1273e+00, 1.0851e+02, 1.4153e+02, 1.4735e+02],\n",
            "        [5.5632e+01, 5.8682e+01, 1.1425e+02, 7.5504e+01],\n",
            "        [2.4760e+01, 1.0893e+02, 3.1434e+01, 1.2522e+02],\n",
            "        [1.0663e+02, 7.8757e+01, 1.8307e+02, 1.4277e+02],\n",
            "        [5.9748e+01, 9.9432e+01, 7.4250e+01, 1.1512e+02],\n",
            "        [3.8725e-02, 1.0085e+02, 1.3107e+01, 1.1771e+02],\n",
            "        [1.6975e-01, 7.3182e+01, 9.6199e+00, 8.6369e+01],\n",
            "        [2.0794e+02, 7.1213e+01, 2.2293e+02, 1.2609e+02],\n",
            "        [4.2650e-01, 1.1792e+02, 2.2047e+01, 1.4738e+02],\n",
            "        [3.0426e+01, 1.2553e+02, 4.4765e+01, 1.4224e+02],\n",
            "        [1.9789e+02, 0.0000e+00, 2.0829e+02, 9.0586e+00],\n",
            "        [3.2147e-01, 1.3780e+02, 3.8736e+01, 1.8049e+02],\n",
            "        [1.9918e+01, 1.3075e+02, 6.5756e+01, 1.5166e+02],\n",
            "        [1.0867e+00, 1.2088e+02, 2.3827e+01, 1.7985e+02],\n",
            "        [2.0224e+02, 6.4929e+01, 2.2126e+02, 1.0521e+02],\n",
            "        [5.5444e+01, 1.0174e+02, 6.9542e+01, 1.1693e+02],\n",
            "        [0.0000e+00, 1.1736e+02, 7.6446e+00, 1.3350e+02],\n",
            "        [1.8529e-01, 7.7613e+01, 9.5989e+00, 9.0887e+01],\n",
            "        [1.7212e+01, 1.0159e+02, 3.1498e+01, 1.1689e+02],\n",
            "        [4.2819e+01, 1.2122e+02, 8.6790e+01, 1.4497e+02],\n",
            "        [2.4475e+01, 1.2089e+02, 3.1344e+01, 1.3777e+02],\n",
            "        [1.6043e-01, 6.8677e+01, 9.6432e+00, 8.1901e+01],\n",
            "        [1.9850e-01, 1.1137e+02, 9.6508e+00, 1.2473e+02],\n",
            "        [2.2030e+01, 1.0155e+02, 3.5997e+01, 1.1709e+02],\n",
            "        [1.6978e+02, 6.6434e+01, 2.0547e+02, 9.8068e+01],\n",
            "        [1.9743e+01, 6.3954e+01, 2.0470e+02, 1.6700e+02],\n",
            "        [1.0617e+01, 1.2717e+02, 4.2078e+01, 1.5493e+02],\n",
            "        [0.0000e+00, 9.6005e+01, 7.0694e+00, 1.1307e+02],\n",
            "        [2.0326e-01, 5.8659e+01, 9.5877e+00, 7.1858e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.5950, 0.5869, 0.5666, 0.5648, 0.5648, 0.5616, 0.5590, 0.5588, 0.5578,\n",
            "        0.5570, 0.5563, 0.5554, 0.5526, 0.5511, 0.5494, 0.5491, 0.5488, 0.5478,\n",
            "        0.5476, 0.5473, 0.5459, 0.5404, 0.5395, 0.5395, 0.5387, 0.5383, 0.5378,\n",
            "        0.5369, 0.5355, 0.5343, 0.5343, 0.5321, 0.5320, 0.5318, 0.5295, 0.5280,\n",
            "        0.5277, 0.5275, 0.5261, 0.5255, 0.5248, 0.5248, 0.5240, 0.5239, 0.5239,\n",
            "        0.5237, 0.5236, 0.5233, 0.5232, 0.5232, 0.5232, 0.5231, 0.5214, 0.5213,\n",
            "        0.5213, 0.5210, 0.5205, 0.5205, 0.5198, 0.5197, 0.5196, 0.5188, 0.5181,\n",
            "        0.5157, 0.5156, 0.5153, 0.5151, 0.5141, 0.5140, 0.5127, 0.5119, 0.5115,\n",
            "        0.5099, 0.5099, 0.5099, 0.5089, 0.5088, 0.5088, 0.5082, 0.5081, 0.5076,\n",
            "        0.5075, 0.5070, 0.5057, 0.5053, 0.5053, 0.5052, 0.5038, 0.5036, 0.5035,\n",
            "        0.5029, 0.5026, 0.5025, 0.5024, 0.5006, 0.5003, 0.5001, 0.5000, 0.4998,\n",
            "        0.4994], device='cuda:0', grad_fn=<IndexBackward0>)}, {'boxes': tensor([[9.4153e+01, 1.8190e+02, 1.2267e+02, 2.1772e+02],\n",
            "        [6.4734e+01, 1.7438e+02, 9.6353e+01, 2.0720e+02],\n",
            "        [9.3332e+01, 1.6742e+02, 1.1283e+02, 2.0731e+02],\n",
            "        [4.8321e+01, 1.8847e+02, 7.6753e+01, 2.1958e+02],\n",
            "        [7.8008e+01, 1.7150e+02, 1.0834e+02, 2.0595e+02],\n",
            "        [7.8993e+01, 1.8674e+02, 1.0728e+02, 2.1898e+02],\n",
            "        [9.9828e+01, 1.9003e+02, 1.1457e+02, 2.1892e+02],\n",
            "        [5.8882e+01, 1.9310e+02, 9.7901e+01, 2.1794e+02],\n",
            "        [1.1818e+02, 1.8821e+02, 1.4343e+02, 2.2011e+02],\n",
            "        [4.4996e+01, 1.9715e+02, 6.2930e+01, 2.1705e+02],\n",
            "        [1.6720e+02, 3.8240e+01, 1.7815e+02, 6.2846e+01],\n",
            "        [1.1732e+02, 1.7503e+02, 1.4462e+02, 2.0971e+02],\n",
            "        [2.3853e+01, 2.0117e+02, 3.9046e+01, 2.1847e+02],\n",
            "        [7.4989e+01, 1.8417e+02, 8.9812e+01, 2.0233e+02],\n",
            "        [3.9724e+01, 1.8968e+02, 6.7450e+01, 2.1937e+02],\n",
            "        [1.6842e+02, 3.5026e+01, 1.7660e+02, 5.2369e+01],\n",
            "        [9.1820e+01, 1.7469e+02, 1.3228e+02, 2.0008e+02],\n",
            "        [2.2948e+01, 1.9360e+02, 6.4485e+01, 2.1665e+02],\n",
            "        [9.1278e+01, 1.7565e+02, 1.0514e+02, 2.0699e+02],\n",
            "        [3.6953e+01, 1.9990e+02, 5.2303e+01, 2.1851e+02],\n",
            "        [2.9898e+01, 1.9794e+02, 4.5328e+01, 2.1673e+02],\n",
            "        [2.0409e+02, 2.0122e+02, 2.2126e+02, 2.1816e+02],\n",
            "        [4.0635e+01, 1.9922e+02, 4.8842e+01, 2.1737e+02],\n",
            "        [1.4701e+01, 2.1987e+02, 3.9798e+01, 2.2389e+02],\n",
            "        [1.6677e+02, 6.7914e+01, 1.7831e+02, 9.1609e+01],\n",
            "        [1.9704e+02, 2.0341e+02, 2.0378e+02, 2.1696e+02],\n",
            "        [2.0234e+02, 2.0587e+02, 2.1237e+02, 2.1745e+02],\n",
            "        [9.8177e+01, 0.0000e+00, 1.0810e+02, 9.5497e+00],\n",
            "        [1.6820e+02, 4.9263e+01, 1.7487e+02, 6.5700e+01],\n",
            "        [1.9881e+02, 2.0026e+02, 2.1341e+02, 2.1520e+02],\n",
            "        [1.1595e-01, 1.9769e+02, 1.2608e+01, 2.2182e+02],\n",
            "        [1.6784e+02, 6.9633e+01, 1.7534e+02, 8.7522e+01],\n",
            "        [1.8341e+02, 2.0280e+02, 1.9048e+02, 2.1768e+02],\n",
            "        [1.1603e+02, 1.6700e+02, 1.4461e+02, 1.9675e+02],\n",
            "        [1.8880e+02, 2.0268e+02, 1.9637e+02, 2.1772e+02],\n",
            "        [4.9600e+01, 1.9408e+02, 6.5683e+01, 2.1247e+02],\n",
            "        [9.9507e+01, 1.7474e+02, 1.1579e+02, 2.0332e+02],\n",
            "        [1.6819e+02, 3.8877e+01, 1.7479e+02, 5.7535e+01],\n",
            "        [1.2357e+02, 1.6990e+02, 1.4188e+02, 1.9039e+02],\n",
            "        [1.2775e+02, 1.8652e+02, 1.4222e+02, 2.1492e+02],\n",
            "        [7.3408e+01, 0.0000e+00, 8.3042e+01, 9.5306e+00],\n",
            "        [1.6508e+02, 1.3483e+02, 1.7631e+02, 1.5936e+02],\n",
            "        [2.0168e+02, 2.0629e+02, 2.1666e+02, 2.2259e+02],\n",
            "        [4.6605e-01, 2.0709e+02, 9.5502e+00, 2.2105e+02],\n",
            "        [1.6610e+02, 9.7020e+01, 1.7884e+02, 1.2120e+02],\n",
            "        [1.3067e+01, 2.0669e+02, 2.7266e+01, 2.2257e+02],\n",
            "        [3.8934e+01, 1.9429e+02, 5.4596e+01, 2.1259e+02],\n",
            "        [1.6412e+02, 1.9016e+02, 1.7692e+02, 2.1506e+02],\n",
            "        [1.9041e+00, 2.1232e+02, 1.2132e+01, 2.2350e+02],\n",
            "        [6.7286e+01, 1.9504e+02, 8.6497e+01, 2.1604e+02],\n",
            "        [1.6673e+02, 7.6924e+01, 1.7879e+02, 1.0137e+02],\n",
            "        [1.6495e+02, 1.4357e+02, 1.7629e+02, 1.6878e+02],\n",
            "        [1.2220e+02, 1.9479e+02, 1.3991e+02, 2.1538e+02],\n",
            "        [8.4004e+01, 1.9390e+02, 1.0310e+02, 2.1612e+02],\n",
            "        [1.9496e+02, 0.0000e+00, 1.9958e+02, 6.9742e+00],\n",
            "        [6.9244e+01, 0.0000e+00, 7.9431e+01, 9.6214e+00],\n",
            "        [5.4791e+01, 1.7720e+02, 8.7017e+01, 2.0538e+02],\n",
            "        [1.9234e+02, 0.0000e+00, 2.0200e+02, 9.5420e+00],\n",
            "        [1.6780e+02, 3.1033e+01, 1.8092e+02, 5.6206e+01],\n",
            "        [2.0525e+02, 2.0480e+02, 2.1603e+02, 2.1648e+02],\n",
            "        [1.6682e+02, 5.4700e+01, 1.7851e+02, 7.8884e+01],\n",
            "        [1.9142e+02, 2.0013e+02, 2.0639e+02, 2.1560e+02],\n",
            "        [8.1262e+01, 0.0000e+00, 9.1250e+01, 9.6468e+00],\n",
            "        [4.5389e+01, 2.0242e+02, 5.5505e+01, 2.1699e+02],\n",
            "        [1.6673e+02, 1.0062e+02, 1.7442e+02, 1.1929e+02],\n",
            "        [1.6612e+02, 1.0546e+02, 1.7916e+02, 1.3020e+02],\n",
            "        [1.9167e+02, 2.0678e+02, 2.0668e+02, 2.2242e+02],\n",
            "        [3.4702e+00, 2.0594e+02, 1.8349e+01, 2.2261e+02],\n",
            "        [8.4392e+00, 2.1227e+02, 1.8974e+01, 2.2362e+02],\n",
            "        [2.1594e+01, 2.0665e+02, 3.6405e+01, 2.2247e+02],\n",
            "        [1.9701e+02, 2.2168e+02, 2.2318e+02, 2.2400e+02],\n",
            "        [1.6504e+02, 1.9885e+02, 1.8001e+02, 2.1619e+02],\n",
            "        [2.6554e+01, 0.0000e+00, 3.5851e+01, 9.4721e+00],\n",
            "        [3.1090e+01, 0.0000e+00, 4.0751e+01, 9.4971e+00],\n",
            "        [1.6462e+02, 1.6102e+02, 1.7663e+02, 1.8667e+02],\n",
            "        [3.8980e+01, 1.8607e+02, 8.1678e+01, 2.0712e+02],\n",
            "        [6.3237e+01, 0.0000e+00, 7.3132e+01, 9.6897e+00],\n",
            "        [1.2501e+02, 1.8250e+02, 1.4299e+02, 2.0504e+02],\n",
            "        [1.6440e+02, 1.7098e+02, 1.7691e+02, 1.9887e+02],\n",
            "        [9.1345e+01, 0.0000e+00, 1.0154e+02, 9.5158e+00],\n",
            "        [5.1023e+01, 0.0000e+00, 6.0924e+01, 1.1018e+01],\n",
            "        [1.6630e+02, 8.8950e+01, 1.7996e+02, 1.0712e+02],\n",
            "        [1.9518e+02, 2.1326e+02, 2.0644e+02, 2.2400e+02],\n",
            "        [1.6656e+02, 1.1091e+02, 1.7457e+02, 1.2925e+02],\n",
            "        [0.0000e+00, 2.0949e+02, 4.0626e+01, 2.2376e+02],\n",
            "        [1.0678e+02, 0.0000e+00, 1.1744e+02, 9.6699e+00],\n",
            "        [6.5363e-01, 2.1895e+02, 1.9599e+01, 2.2395e+02],\n",
            "        [4.4131e+01, 0.0000e+00, 4.9932e+01, 9.7821e+00],\n",
            "        [9.3864e+01, 1.6379e+02, 1.2537e+02, 1.9394e+02],\n",
            "        [1.3267e+02, 0.0000e+00, 1.4328e+02, 9.7199e+00],\n",
            "        [1.6557e+02, 1.2085e+02, 1.7973e+02, 1.4634e+02],\n",
            "        [3.2448e+01, 1.9237e+02, 4.7332e+01, 2.0974e+02],\n",
            "        [6.8925e-01, 2.1908e+02, 9.0813e+00, 2.2385e+02],\n",
            "        [4.3410e+01, 1.9210e+02, 6.0696e+01, 2.1039e+02],\n",
            "        [1.2822e+02, 0.0000e+00, 1.3883e+02, 9.7230e+00],\n",
            "        [1.1137e+02, 0.0000e+00, 1.2196e+02, 9.6901e+00],\n",
            "        [1.9036e+01, 1.9758e+02, 3.4224e+01, 2.1389e+02],\n",
            "        [1.6592e+02, 1.2194e+02, 1.7331e+02, 1.4054e+02],\n",
            "        [5.4354e+01, 0.0000e+00, 6.4107e+01, 9.5636e+00],\n",
            "        [1.6726e+02, 5.7712e+01, 1.7405e+02, 7.5977e+01]], device='cuda:0',\n",
            "       grad_fn=<StackBackward0>), 'labels': tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
            "        1, 1, 1, 1], device='cuda:0'), 'scores': tensor([0.6306, 0.6265, 0.6212, 0.6192, 0.6106, 0.6033, 0.6021, 0.5916, 0.5864,\n",
            "        0.5851, 0.5842, 0.5834, 0.5834, 0.5827, 0.5826, 0.5787, 0.5767, 0.5759,\n",
            "        0.5751, 0.5747, 0.5706, 0.5696, 0.5694, 0.5691, 0.5676, 0.5664, 0.5645,\n",
            "        0.5632, 0.5629, 0.5627, 0.5624, 0.5623, 0.5622, 0.5612, 0.5605, 0.5595,\n",
            "        0.5589, 0.5588, 0.5584, 0.5581, 0.5576, 0.5573, 0.5571, 0.5567, 0.5531,\n",
            "        0.5517, 0.5510, 0.5502, 0.5501, 0.5498, 0.5489, 0.5488, 0.5485, 0.5484,\n",
            "        0.5476, 0.5476, 0.5469, 0.5465, 0.5456, 0.5453, 0.5448, 0.5447, 0.5440,\n",
            "        0.5439, 0.5438, 0.5436, 0.5432, 0.5432, 0.5421, 0.5414, 0.5409, 0.5408,\n",
            "        0.5401, 0.5398, 0.5396, 0.5395, 0.5395, 0.5380, 0.5375, 0.5372, 0.5371,\n",
            "        0.5365, 0.5359, 0.5357, 0.5355, 0.5345, 0.5339, 0.5335, 0.5332, 0.5310,\n",
            "        0.5308, 0.5306, 0.5304, 0.5304, 0.5301, 0.5298, 0.5295, 0.5295, 0.5293,\n",
            "        0.5292], device='cuda:0', grad_fn=<IndexBackward0>)}]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-94a8c8bcb5f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_test_Faster_RCNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls_testing_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlis_testing_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-12-660e7bd4eef6>\u001b[0m in \u001b[0;36mtrain_and_test_Faster_RCNN\u001b[0;34m(training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device, num_classes)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m#train_and_test(faster_rcnn, training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mfaster_rcnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtesting_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfaster_rcnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_and_test_YOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtesting_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mls_testing_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlis_testing_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-4-71d46ed5a339>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, testing_loader, criterion, print_incorrect_images)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"output: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m   1172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1174\u001b[0;31m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0m\u001b[1;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                label_smoothing=self.label_smoothing)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[1;32m   3024\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: cross_entropy_loss(): argument 'input' (position 1) must be Tensor, not list"
          ]
        }
      ],
      "source": [
        "train_and_test_Faster_RCNN(training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo4rOP5risNx"
      },
      "outputs": [],
      "source": [
        "#TODO: Get these working\n",
        "#train_and_test_YOLO(training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device, num_classes)\n",
        "#train_and_test_SSD(training_loader, testing_loader, ls_testing_loader, lis_testing_loader, device, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2cP_lViuIfw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}