{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "9KL9nUitbYwh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this to connect to Google Drive in Google Colab\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21IBzqnOnAgp",
        "outputId": "2a30754a-9bdc-4b25-d871-b9b3f11ac320"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use this to unzip file in Google Colab\n",
        "!unzip drive/MyDrive/data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdiBo5l6hfSd",
        "outputId": "51875989-4590-4be8-c8a2-3d56cd912606"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  drive/MyDrive/data.zip\n",
            "replace __MACOSX/._data? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "ECpQROeamJfA"
      },
      "outputs": [],
      "source": [
        "class image_data_set(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        return {'data': self.data[index], 'label': self.labels[index]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qyIy4drE2BUt"
      },
      "outputs": [],
      "source": [
        "def get_image_tensor(file_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    \n",
        "    image = Image.open(file_path)\n",
        "    return transform(image)\n",
        "\n",
        "def get_data_and_labels(directory_path, label):\n",
        "    image_tensors, labels = [], []\n",
        "    for file in os.listdir(directory_path):\n",
        "        if file.endswith(\".JPG\"):\n",
        "            file_path = directory_path + file\n",
        "            image_tensor = get_image_tensor(file_path)\n",
        "            image_tensors.append(image_tensor)\n",
        "            labels.append(label)\n",
        "            \n",
        "    return image_tensors, labels\n",
        "    \n",
        "def get_data_sets(): \n",
        "    present_file_path = \"data/MP152_ODOT009_REPELCAM/present/\"\n",
        "    not_present_file_path = \"data/MP152_ODOT009_REPELCAM/not_present/\"\n",
        "    \n",
        "    present_data, present_labels = get_data_and_labels(present_file_path, 1)\n",
        "    not_present_data, not_present_labels = get_data_and_labels(not_present_file_path, 0)\n",
        "    \n",
        "    print(\"Number of wildlife present photos: \" + str(len(present_data)))\n",
        "    print(\"Number of no wildlife present photos: \" + str(len(not_present_data)))\n",
        "    \n",
        "    data = present_data + not_present_data\n",
        "    labels = present_labels + not_present_labels\n",
        "    \n",
        "    training_data, testing_data, training_labels, testing_labels = train_test_split(data, labels)\n",
        "    \n",
        "    print(\"\\nNumber of training photos: \" + str(len(training_data)))\n",
        "    print(\"Number of testing photos: \" + str(len(testing_data)))\n",
        "    \n",
        "    training_data_set = image_data_set(training_data, training_labels)\n",
        "    testing_data_set = image_data_set(testing_data, testing_labels)\n",
        "    \n",
        "    return training_data_set, testing_data_set\n",
        "\n",
        "def get_loaders(training_data_set, testing_data_set, batch_size):\n",
        "    training_loader = torch.utils.data.DataLoader(dataset = training_data_set,\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  shuffle = True)\n",
        "\n",
        "    testing_loader = torch.utils.data.DataLoader(dataset = testing_data_set,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 shuffle = True)\n",
        "    \n",
        "    return training_loader, testing_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wpeG79qU2Tdh"
      },
      "outputs": [],
      "source": [
        "def train(model, training_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(training_loader):\n",
        "        data, labels = data['data'].to(device), data['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    loss = running_loss/len(training_loader.dataset)\n",
        "    accuracy = num_correct/len(training_loader.dataset)\n",
        "    return loss, accuracy\n",
        "\n",
        "def test(model, testing_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(testing_loader):\n",
        "        data, labels = data['data'].to(device), data['label'].to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "    \n",
        "    loss = running_loss/len(testing_loader.dataset)\n",
        "    accuracy = num_correct/len(testing_loader.dataset)\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "ZBTEy1kg3pem"
      },
      "outputs": [],
      "source": [
        "def train_and_test(model, training_loader, testing_loader, device):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    \n",
        "    for epoch in range(5):\n",
        "        print(\"epoch: \" + str(epoch))\n",
        "        \n",
        "        training_loss, training_accuracy = train(model, training_loader, criterion, optimizer)\n",
        "        print(\"training loss: \" + str(training_loss) + \" and training accuracy: \" + str(training_accuracy))\n",
        "        \n",
        "        testing_loss, testing_accuracy = test(model, testing_loader, criterion)\n",
        "        print(\"testing loss: \" + str(testing_loss) + \" and testing accuracy: \" + str(testing_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "678WuU6g3tuV"
      },
      "outputs": [],
      "source": [
        "def train_and_test_VGG11(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing VGG11\")\n",
        "    vgg11 = models.vgg11(weights = models.VGG11_Weights.DEFAULT)\n",
        "    vgg11.classifier[6].out_features = num_classes\n",
        "    train_and_test(vgg11, training_loader, testing_loader, device)\n",
        "\n",
        "def train_and_test_VGG19(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing VGG19\")\n",
        "    vgg19 = models.vgg19(weights = models.VGG19_Weights.DEFAULT)\n",
        "    vgg19.classifier[6].out_features = num_classes\n",
        "    train_and_test(vgg19, training_loader, testing_loader, device)\n",
        "\n",
        "def train_and_test_ResNet50(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing ResNet50\")\n",
        "    resnet50 = models.resnet50(weights = models.ResNet50_Weights.DEFAULT)\n",
        "    resnet50.fc.out_features = num_classes\n",
        "    train_and_test(resnet50, training_loader, testing_loader, device)\n",
        "\n",
        "def train_and_test_ResNet152(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing ResNet152\")\n",
        "    resnet152 = models.resnet152(weights = models.ResNet152_Weights.DEFAULT)\n",
        "    resnet152.fc.out_features = num_classes\n",
        "    train_and_test(resnet152, training_loader, testing_loader, device)\n",
        "    \n",
        "def train_and_test_AlexNet(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing AlexNet\")\n",
        "    alexnet = models.alexnet(weights = models.AlexNet_Weights.DEFAULT)\n",
        "    alexnet.classifier[6].out_features = num_classes\n",
        "    train_and_test(alexnet, training_loader, testing_loader, device)\n",
        "\n",
        "def train_and_test_SSD(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing SSD\")\n",
        "    ssd300_vgg16 = models.detection.ssd300_vgg16(weights = models.detection.SSD300_VGG16_Weights.COCO_V1)\n",
        "    train_and_test(ssd300_vgg16, training_loader, testing_loader, device)\n",
        "    \n",
        "def train_and_test_Faster_RCNN(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing Faster R-CNN\")\n",
        "    faster_rcnn = models.detection.fasterrcnn_resnet50_fpn_v2(weights = models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT)\n",
        "    faster_rcnn.roi_heads.box_predictor.bbox_pred.out_features = num_classes\n",
        "    train_and_test(faster_rcnn, training_loader, testing_loader, device)\n",
        "    \n",
        "def train_and_test_YOLO(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing YOLO\")\n",
        "    yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "    train_and_test(yolo, training_loader, testing_loader, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Orchestration"
      ],
      "metadata": {
        "id": "dAAF1fMaol0q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89jqZ2L-3yeo",
        "outputId": "7b9e2131-c26b-41ef-a352-c5b5d73ca89f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of wildlife present photos: 223\n",
            "Number of no wildlife present photos: 363\n",
            "\n",
            "Number of training photos: 439\n",
            "Number of testing photos: 147\n"
          ]
        }
      ],
      "source": [
        "num_classes = 2\n",
        "batch_size = 10\n",
        "\n",
        "training_data_set, testing_data_set = get_data_sets()\n",
        "training_loader, testing_loader = get_loaders(training_data_set, testing_data_set, batch_size)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "MnFhuIILpnHs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec60273c-45a3-4bfd-8b29-427fd417f2eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and Testing VGG11\n",
            "epoch: 0\n",
            "training loss: 0.13112048455142758 and training accuracy: 0.6993166287015945\n",
            "testing loss: 0.05869498869188789 and testing accuracy: 0.7482993197278912\n",
            "epoch: 1\n",
            "training loss: 0.03983639561675133 and training accuracy: 0.806378132118451\n",
            "testing loss: 0.033517539298453296 and testing accuracy: 0.9115646258503401\n",
            "epoch: 2\n",
            "training loss: 0.036134377605619085 and training accuracy: 0.8587699316628702\n",
            "testing loss: 0.030418635377673066 and testing accuracy: 0.8843537414965986\n",
            "epoch: 3\n",
            "training loss: 0.027773917366268965 and training accuracy: 0.8838268792710706\n",
            "testing loss: 0.02654149920559254 and testing accuracy: 0.9251700680272109\n",
            "epoch: 4\n",
            "training loss: 0.025258682099656798 and training accuracy: 0.9043280182232346\n",
            "testing loss: 0.023901004572303926 and testing accuracy: 0.9183673469387755\n"
          ]
        }
      ],
      "source": [
        "train_and_test_VGG11(training_loader, testing_loader, device, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test_VGG19(training_loader, testing_loader, device, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DI2-I680rObU",
        "outputId": "0685f3ec-8ae3-4f46-f5ed-717d554b380e"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and Testing VGG19\n",
            "epoch: 0\n",
            "training loss: 0.1013374178922801 and training accuracy: 0.7312072892938497\n",
            "testing loss: 0.04370916259734809 and testing accuracy: 0.8639455782312925\n",
            "epoch: 1\n",
            "training loss: 0.041141403300140336 and training accuracy: 0.8200455580865603\n",
            "testing loss: 0.03754961703504835 and testing accuracy: 0.8843537414965986\n",
            "epoch: 2\n",
            "training loss: 0.03266759247334509 and training accuracy: 0.8496583143507973\n",
            "testing loss: 0.031066886624511406 and testing accuracy: 0.9115646258503401\n",
            "epoch: 3\n",
            "training loss: 0.03429192949960471 and training accuracy: 0.856492027334852\n",
            "testing loss: 0.044656122420109856 and testing accuracy: 0.8231292517006803\n",
            "epoch: 4\n",
            "training loss: 0.025499521608301066 and training accuracy: 0.9020501138952164\n",
            "testing loss: 0.021106130348480478 and testing accuracy: 0.9183673469387755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test_ResNet50(training_loader, testing_loader, device, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oFtdz7bIipGV",
        "outputId": "9d618f5a-5075-41cc-ae05-9d08687511d6"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and Testing ResNet50\n",
            "epoch: 0\n",
            "training loss: 0.3140658556328819 and training accuracy: 0.5375854214123007\n",
            "testing loss: 0.06684430863480179 and testing accuracy: 0.891156462585034\n",
            "epoch: 1\n",
            "training loss: 0.04184125690532165 and training accuracy: 0.8838268792710706\n",
            "testing loss: 0.038140732465552635 and testing accuracy: 0.9183673469387755\n",
            "epoch: 2\n",
            "training loss: 0.02655530384909319 and training accuracy: 0.9066059225512528\n",
            "testing loss: 0.03527047913394818 and testing accuracy: 0.9251700680272109\n",
            "epoch: 3\n",
            "training loss: 0.022993019245276417 and training accuracy: 0.9157175398633257\n",
            "testing loss: 0.028924452977216974 and testing accuracy: 0.9319727891156463\n",
            "epoch: 4\n",
            "training loss: 0.019036892046282124 and training accuracy: 0.9248291571753986\n",
            "testing loss: 0.02365854581450524 and testing accuracy: 0.9387755102040817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test_ResNet152(training_loader, testing_loader, device, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42RgiJSWrmQo",
        "outputId": "ff98c694-6627-4d30-9aee-2a0ca907727e"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and Testing ResNet152\n",
            "epoch: 0\n",
            "training loss: 0.28502759133764716 and training accuracy: 0.5421412300683371\n",
            "testing loss: 0.06027526811373477 and testing accuracy: 0.891156462585034\n",
            "epoch: 1\n",
            "training loss: 0.0359577101004015 and training accuracy: 0.8678815489749431\n",
            "testing loss: 0.02974418202275727 and testing accuracy: 0.9251700680272109\n",
            "epoch: 2\n",
            "training loss: 0.023651025315284187 and training accuracy: 0.89749430523918\n",
            "testing loss: 0.0232221309070279 and testing accuracy: 0.9115646258503401\n",
            "epoch: 3\n",
            "training loss: 0.018335462329327923 and training accuracy: 0.9384965831435079\n",
            "testing loss: 0.02024666881378816 and testing accuracy: 0.9183673469387755\n",
            "epoch: 4\n",
            "training loss: 0.014728586374016178 and training accuracy: 0.9430523917995444\n",
            "testing loss: 0.016580290281448234 and testing accuracy: 0.9523809523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_test_AlexNet(training_loader, testing_loader, device, num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgW0CbFLiq2M",
        "outputId": "ab23fb09-9a8e-4bfc-d6ad-e58222def957"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training and Testing AlexNet\n",
            "epoch: 0\n",
            "training loss: 0.15341773968622732 and training accuracy: 0.6788154897494305\n",
            "testing loss: 0.043597612149861395 and testing accuracy: 0.8775510204081632\n",
            "epoch: 1\n",
            "training loss: 0.03743935920349015 and training accuracy: 0.8587699316628702\n",
            "testing loss: 0.04753332724477969 and testing accuracy: 0.8571428571428571\n",
            "epoch: 2\n",
            "training loss: 0.0325610366372014 and training accuracy: 0.8838268792710706\n",
            "testing loss: 0.02820405450199737 and testing accuracy: 0.9183673469387755\n",
            "epoch: 3\n",
            "training loss: 0.02978592531666465 and training accuracy: 0.8815489749430524\n",
            "testing loss: 0.029296493550547125 and testing accuracy: 0.8843537414965986\n",
            "epoch: 4\n",
            "training loss: 0.02730277657576737 and training accuracy: 0.9020501138952164\n",
            "testing loss: 0.02709394561595657 and testing accuracy: 0.9183673469387755\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TODO: Get both of these working\n",
        "#train_and_test_Faster_RCNN(training_loader, testing_loader, device, num_classes)\n",
        "#train_and_test_YOLO(training_loader, testing_loader, device, num_classes)\n",
        "#train_and_test_SSD(training_loader, testing_loader, device, num_classes)"
      ],
      "metadata": {
        "id": "wo4rOP5risNx"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "M2cP_lViuIfw"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}