{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9KL9nUitbYwh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ECpQROeamJfA"
      },
      "outputs": [],
      "source": [
        "class image_data_set(torch.utils.data.Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "  \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "  \n",
        "    def __getitem__(self, index):\n",
        "        return {'data': self.data[index], 'label': self.labels[index]}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "qyIy4drE2BUt"
      },
      "outputs": [],
      "source": [
        "def get_image_tensor(file_path):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "    ])\n",
        "    \n",
        "    image = Image.open(file_path)\n",
        "    return transform(image)\n",
        "\n",
        "def get_data_and_labels(directory_path, label):\n",
        "    image_tensors, labels = [], []\n",
        "    for file in os.listdir(directory_path):\n",
        "        if file.endswith(\".JPG\"):\n",
        "            file_path = directory_path + file\n",
        "            image_tensor = get_image_tensor(file_path)\n",
        "            image_tensors.append(image_tensor)\n",
        "            labels.append(label)\n",
        "            \n",
        "    return image_tensors, labels\n",
        "    \n",
        "def get_data_sets(): \n",
        "    present_file_path = \"data/MP152_ODOT009_REPELCAM/present/\"\n",
        "    not_present_file_path = \"data/MP152_ODOT009_REPELCAM/not_present/\"\n",
        "    \n",
        "    present_data, present_labels = get_data_and_labels(present_file_path, 1)\n",
        "    not_present_data, not_present_labels = get_data_and_labels(not_present_file_path, 1)\n",
        "    \n",
        "    print(\"Number of wildlife present photos: \" + str(len(present_data)))\n",
        "    print(\"Number of no wildlife present photos: \" + str(len(not_present_data)))\n",
        "    \n",
        "    data = present_data + not_present_data\n",
        "    labels = present_labels + not_present_labels\n",
        "    \n",
        "    training_data, testing_data, training_labels, testing_labels = train_test_split(data, labels)\n",
        "    \n",
        "    print(\"\\nNumber of training photos: \" + str(len(training_data)))\n",
        "    print(\"Number of testing photos: \" + str(len(testing_data)))\n",
        "    \n",
        "    training_data_set = image_data_set(training_data, training_labels)\n",
        "    testing_data_set = image_data_set(testing_data, testing_labels)\n",
        "    \n",
        "    return training_data_set, testing_data_set\n",
        "\n",
        "def get_loaders(training_data_set, testing_data_set, batch_size):\n",
        "    training_loader = torch.utils.data.DataLoader(dataset = training_data_set,\n",
        "                                                  batch_size = batch_size,\n",
        "                                                  shuffle = True)\n",
        "\n",
        "    testing_loader = torch.utils.data.DataLoader(dataset = testing_data_set,\n",
        "                                                 batch_size = batch_size,\n",
        "                                                 shuffle = True)\n",
        "    \n",
        "    return training_loader, testing_loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "wpeG79qU2Tdh"
      },
      "outputs": [],
      "source": [
        "def train(model, training_loader, criterion, optimizer):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(training_loader):\n",
        "        data, labels = data['data'].to(device), data['label'].to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    \n",
        "    loss = running_loss/len(training_loader.dataset)\n",
        "    accuracy = num_correct/len(training_loader.dataset)\n",
        "    return loss, accuracy\n",
        "\n",
        "def test(model, testing_loader, criterion):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    num_correct = 0\n",
        "    for i, data in enumerate(testing_loader):\n",
        "        data, labels = data['data'].to(device), data['label'].to(device)\n",
        "        output = model(data)\n",
        "        loss = criterion(output, labels)\n",
        "        running_loss += loss.item()\n",
        "        _, predictions = torch.max(output.data, 1)\n",
        "        num_correct += (predictions == labels).sum().item()\n",
        "    \n",
        "    loss = running_loss/len(testing_loader.dataset)\n",
        "    accuracy = num_correct/len(testing_loader.dataset)\n",
        "    return loss, accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ZBTEy1kg3pem"
      },
      "outputs": [],
      "source": [
        "def train_and_test(model, training_loader, testing_loader, device):\n",
        "    model.to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    \n",
        "    for epoch in range(3):\n",
        "        print(\"epoch: \" + str(epoch))\n",
        "        \n",
        "        training_loss, training_accuracy = train(model, training_loader, criterion, optimizer)\n",
        "        print(\"training loss: \" + str(training_loss) + \" and training accuracy: \" + str(training_accuracy))\n",
        "        \n",
        "        testing_loss, testing_accuracy = test(model, testing_loader, criterion)\n",
        "        print(\"testing loss: \" + str(testing_loss) + \" and testing accuracy: \" + str(testing_accuracy))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "678WuU6g3tuV"
      },
      "outputs": [],
      "source": [
        "def train_and_test_VGG(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing VGG\")\n",
        "    vgg11 = models.vgg11(weights = models.VGG11_Weights.DEFAULT)\n",
        "    vgg11.classifier[6].out_features = num_classes\n",
        "    train_and_test(vgg11, training_loader, testing_loader, device)\n",
        "\n",
        "def train_and_test_ResNet(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing ResNet\")\n",
        "    resnet50 = models.resnet50(weights = models.ResNet50_Weights.DEFAULT)\n",
        "    resnet50.fc.out_features = num_classes\n",
        "    train_and_test(resnet50, training_loader, testing_loader, device)\n",
        "    \n",
        "def train_and_test_AlexNet(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing AlexNet\")\n",
        "    alexnet = models.alexnet(weights = models.AlexNet_Weights.IMAGENET1K_V1)\n",
        "    alexnet.classifier[6].out_features = num_classes\n",
        "    train_and_test(alexnet, training_loader, testing_loader, device)\n",
        "    \n",
        "def train_and_test_Faster_RCNN(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing Faster R-CNN\")\n",
        "    faster_rcnn = models.detection.fasterrcnn_resnet50_fpn_v2(weights = models.detection.FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT)\n",
        "    faster_rcnn.roi_heads.box_predictor.bbox_pred.out_features = num_classes\n",
        "    train_and_test(faster_rcnn, training_loader, testing_loader, device)\n",
        "    \n",
        "def train_and_test_YOLO(training_loader, testing_loader, device, num_classes):\n",
        "    print(\"\\nTraining and Testing YOLO\")\n",
        "    yolo = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)\n",
        "    train_and_test(yolo, training_loader, testing_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "89jqZ2L-3yeo",
        "outputId": "a41e7166-9fa8-4e1d-c18d-9a97d06b1fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of wildlife present photos: 223\n",
            "Number of no wildlife present photos: 363\n",
            "\n",
            "Number of training photos: 439\n",
            "Number of testing photos: 147\n",
            "\n",
            "Training and Testing VGG\n",
            "epoch: 0\n",
            "training loss: 0.03995401678730549 and training accuracy: 0.9544419134396356\n",
            "testing loss: 0.0 and testing accuracy: 1.0\n",
            "epoch: 1\n",
            "training loss: 0.0 and training accuracy: 1.0\n",
            "testing loss: 0.0 and testing accuracy: 1.0\n",
            "epoch: 2\n",
            "training loss: 0.0 and training accuracy: 1.0\n",
            "testing loss: 0.0 and testing accuracy: 1.0\n",
            "\n",
            "Training and Testing ResNet\n",
            "epoch: 0\n",
            "training loss: 0.23673341859180846 and training accuracy: 0.7107061503416856\n",
            "testing loss: 0.011581134032077936 and testing accuracy: 1.0\n",
            "epoch: 1\n",
            "training loss: 0.0010477988715527542 and training accuracy: 1.0\n",
            "testing loss: 0.0037402766661680477 and testing accuracy: 1.0\n",
            "epoch: 2\n",
            "training loss: 0.00012987285506633664 and training accuracy: 1.0\n",
            "testing loss: 0.0027876274151803584 and testing accuracy: 1.0\n",
            "\n",
            "Training and Testing AlexNet\n",
            "epoch: 0\n",
            "training loss: 0.03840427480773829 and training accuracy: 0.9544419134396356\n",
            "testing loss: 0.0 and testing accuracy: 1.0\n",
            "epoch: 1\n",
            "training loss: 0.0 and training accuracy: 1.0\n",
            "testing loss: 0.0 and testing accuracy: 1.0\n",
            "epoch: 2\n",
            "training loss: 0.0 and training accuracy: 1.0\n",
            "testing loss: 0.0 and testing accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "num_classes = 2\n",
        "batch_size = 10\n",
        "\n",
        "training_data_set, testing_data_set = get_data_sets()\n",
        "training_loader, testing_loader = get_loaders(training_data_set, testing_data_set, batch_size)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "train_and_test_VGG(training_loader, testing_loader, device, num_classes)\n",
        "train_and_test_ResNet(training_loader, testing_loader, device, num_classes)\n",
        "train_and_test_AlexNet(training_loader, testing_loader, device, num_classes)\n",
        "\n",
        "#TODO: Get both of these working\n",
        "#train_and_test_Faster_RCNN(training_loader, testing_loader, device, num_classes)\n",
        "#train_and_test_YOLO(training_loader, testing_loader, device, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "MnFhuIILpnHs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}