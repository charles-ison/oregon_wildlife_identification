{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9KL9nUitbYwh"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader\n",
    "from google.colab import drive\n",
    "from datetime import datetime\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TRbIL984Fsjv"
   },
   "source": [
    "# Defining Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "pfRgxikpFqsv"
   },
   "outputs": [],
   "source": [
    "def get_image_tensor(image):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    return transform(image)\n",
    "\n",
    "def get_image_dictionary(directory):\n",
    "    image_dictionary = {}\n",
    "    for file_name in os.listdir(directory):\n",
    "        file_path = os.path.join(directory, file_name)\n",
    "        if os.path.isdir(file_path):\n",
    "            leaf_image_dictionary = get_image_dictionary(file_path)\n",
    "            image_dictionary.update(leaf_image_dictionary)\n",
    "        elif os.path.isfile(file_path):\n",
    "            try:\n",
    "                image = Image.open(file_path)\n",
    "                datetime = image._getexif()[36867]\n",
    "                image_tensor = get_image_tensor(image)\n",
    "                image_dictionary[datetime] = image_tensor\n",
    "            except:\n",
    "                print(\"Truncated image encountered, leaving out of training and testing\")\n",
    "                continue\n",
    "\n",
    "    image_dictionary = OrderedDict(sorted(image_dictionary.items()))\n",
    "    return image_dictionary\n",
    "\n",
    "def get_batched_images(dictionary):\n",
    "    images, batch_images = [], []\n",
    "    previous_time_stamp = None\n",
    "    for key, value in dictionary.items():\n",
    "        time_stamp = datetime.strptime(key, '%Y:%m:%d %H:%M:%S')\n",
    "        if previous_time_stamp == None or (time_stamp - previous_time_stamp).total_seconds() < 60:\n",
    "            batch_images.append(value)\n",
    "        else:\n",
    "            images.append(torch.stack(batch_images))\n",
    "            batch_images = []\n",
    "            batch_images.append(value)\n",
    "\n",
    "        previous_time_stamp = time_stamp\n",
    "\n",
    "    return images\n",
    "\n",
    "def get_max_predictions(batched_images, model, device):\n",
    "    max_predictions = []\n",
    "    for image_batch in batched_images:\n",
    "        # This is to prevent cuda memory issues for large batches\n",
    "        max_prediction = 0\n",
    "        for image in image_batch:\n",
    "            image = torch.unsqueeze(image, dim=0).to(device)\n",
    "            output = model(image).flatten()\n",
    "            max_prediction = max(max_prediction, output.round().item())\n",
    "        max_predictions.append(max_prediction)\n",
    "    return max_predictions\n",
    "\n",
    "def analyze(directory, model, device):\n",
    "    image_dictionary = get_image_dictionary(directory)\n",
    "    print(\"len(image_dictionary):\", len(image_dictionary))\n",
    "\n",
    "    batched_images = get_batched_images(image_dictionary)\n",
    "    print(\"len(batched_images):\", len(batched_images))\n",
    "\n",
    "    max_predictions = get_max_predictions(batched_images, model, device)\n",
    "    print(\"len(max_predictions):\", len(max_predictions))\n",
    "\n",
    "    predicted_total_num_animals = sum(max_predictions)\n",
    "    print(\"predicted_total_num_animals:\", predicted_total_num_animals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dAAF1fMaol0q"
   },
   "source": [
    "\n",
    "# Declaring Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K8oV16oUAaFh",
    "outputId": "fa84c78d-0d10-4f37-97b0-f0b4913db397"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cu118\n",
      "0.15.2+cu118\n",
      "torch.cuda.is_available(): False\n"
     ]
    }
   ],
   "source": [
    "cottonwood_directory = \"Cottonwood_Eastface_6.06_6.13/\"\n",
    "ngilchrist_directory = \"NGilchrist_Eastface_6.06_6.13/\"\n",
    "sgilchrist_directory = \"SGilchrist_Eastface_6.06_6.13/\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "print(\"torch.cuda.is_available(): \" + str(torch.cuda.is_available()))\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K5SQO96ZAaFi"
   },
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G8LXH0PAAaFi",
    "outputId": "d203fdc0-ae8b-4e81-de69-24a2498aafbe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "replace __MACOSX/._SGilchrist_Eastface_6.06_6.13? [y]es, [n]o, [A]ll, [N]one, [r]ename: replace __MACOSX/._Cottonwood_Eastface_6.06_6.13? [y]es, [n]o, [A]ll, [N]one, [r]ename: replace __MACOSX/._NGilchrist_Eastface_6.06_6.13? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "# Use this to connect to Google Drive in Google Colab\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Use this to unzip file in Google Colab\n",
    "!unzip -qq drive/MyDrive/SGilchrist_Eastface_6.06_6.13\n",
    "!unzip -qq drive/MyDrive/Cottonwood_Eastface_6.06_6.13\n",
    "!unzip -qq drive/MyDrive/NGilchrist_Eastface_6.06_6.13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p9tR6BkHAaFj"
   },
   "source": [
    "# Declaring Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "iV_C6HYvAaFk"
   },
   "outputs": [],
   "source": [
    "resnet152 = torch.load(\"batch_count_ResNet152.pt\", map_location=device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Multiple GPUs available, using: \" + str(torch.cuda.device_count()))\n",
    "    resnet152 = nn.DataParallel(resnet152)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oHPSbLA-F4nf"
   },
   "source": [
    "# Orchestrating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M-0JIaB5CqO7",
    "outputId": "9f31c25a-35bb-4adc-c875-8b67a7568469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing Cottonwood\n",
      "len(image_dictionary): 40\n",
      "len(batched_images): 5\n",
      "len(max_predictions): 5\n",
      "predicted_total_num_animals: 0\n",
      "\n",
      "Analyzing NGilchrist\n",
      "len(image_dictionary): 43\n",
      "len(batched_images): 6\n",
      "len(max_predictions): 6\n",
      "predicted_total_num_animals: 0\n",
      "\n",
      "Analyzing SGilchrist\n",
      "len(image_dictionary): 138\n",
      "len(batched_images): 31\n",
      "len(max_predictions): 31\n",
      "predicted_total_num_animals: 0\n"
     ]
    }
   ],
   "source": [
    "print(\"Analyzing Cottonwood\")\n",
    "analyze(cottonwood_directory, resnet152, device)\n",
    "\n",
    "print(\"\\nAnalyzing NGilchrist\")\n",
    "analyze(ngilchrist_directory, resnet152, device)\n",
    "\n",
    "print(\"\\nAnalyzing SGilchrist\")\n",
    "analyze(sgilchrist_directory, resnet152, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5HVBpSqUGYdC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
