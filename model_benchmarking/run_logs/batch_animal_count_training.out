2.0.1+cu117
0.15.2+cu117
torch.cuda.is_available(): True

Feting data from directory:  /nfs/stak/users/isonc/hpc-share/saved_data/training_animal_count/cottonwood_eastface_2022/
loading annotations into memory...
Done (t=0.02s)
creating index...
index created!
Problematic image or label encountered, leaving out of training and validation
Problematic image or label encountered, leaving out of training and validation
Number of images found:  3479
Number of batches found:  596

Feting data from directory:  /nfs/stak/users/isonc/hpc-share/saved_data/training_animal_count/crawford_westface_2022_MP150_ODOT006/
loading annotations into memory...
Done (t=0.01s)
creating index...
index created!
Number of images found:  3468
Number of batches found:  508

Number of training images:  5509
Number of validation images:  1438
Number of batches for training:  882
Number of batches for validation:  222
Multiple GPUs available, using: 2

Training and Validating ResNet34
Epoch: 0
training loss: 0.0013254943011637272
validation MSE: 0.0027077753635664807 and MAE: 0.00530879727470195
batch validation MSE: 0.05529513260466341 and MAE: 0.07133597588619671
Lowest batch validation MAE achieved, saving weights
R^2:  0.7860937767488363
Epoch: 1
training loss: 0.00046290521244360394
validation MSE: 0.0033708308708124764 and MAE: 0.004954744285809314
batch validation MSE: 0.06506932085723567 and MAE: 0.07964165693333557
Epoch: 2
training loss: 0.00030041932456166954
validation MSE: 0.002228228037970293 and MAE: 0.0033290187241470696
batch validation MSE: 0.0594767831788259 and MAE: 0.11332579837222626
Epoch: 3
training loss: 0.00019358349164393706
validation MSE: 0.0022507734826321666 and MAE: 0.003519055914128606
batch validation MSE: 0.06075106887720872 and MAE: 0.11981784411378808
Epoch: 4
training loss: 0.0001328284898062806
validation MSE: 0.0019908209622129074 and MAE: 0.0030021095617320673
batch validation MSE: 0.062336166817611394 and MAE: 0.09216352818986855
Epoch: 5
training loss: 0.00011105337046432675
validation MSE: 0.0020385401148409928 and MAE: 0.0035896264871527984
batch validation MSE: 0.062099326191917104 and MAE: 0.14958407847328228
Epoch: 6
training loss: 9.617824238003312e-05
validation MSE: 0.0019243155224462492 and MAE: 0.0030566424608064794
batch validation MSE: 0.05223338202700035 and MAE: 0.11441607840426334
Epoch: 7
training loss: 8.028730105604983e-05
validation MSE: 0.0020851084058366 and MAE: 0.0034783497110776013
batch validation MSE: 0.0475589742451993 and MAE: 0.06839220647003737
Lowest batch validation MAE achieved, saving weights
R^2:  0.8160206840780229
Epoch: 8
training loss: 5.818140797991894e-05
validation MSE: 0.002446246204264439 and MAE: 0.003135975140052354
batch validation MSE: 0.058163308876113116 and MAE: 0.1049475502726194
Epoch: 9
training loss: 4.2690317539257644e-05
validation MSE: 0.0019656465638504053 and MAE: 0.003243443775036073
batch validation MSE: 0.05611416498766892 and MAE: 0.12459018037797094

Training and Validating Aggregating CNN
Epoch: 0
training loss: 0.002359678264002542
batch validation MSE: 0.2883182490330508 and MAE: 0.1726839189325367
Lowest batch validation MAE achieved, saving weights
R^2:  -0.11534357095858794
Epoch: 1
training loss: 0.0022333517737753755
batch validation MSE: 0.28742187797156926 and MAE: 0.16999030510081095
Lowest batch validation MAE achieved, saving weights
R^2:  -0.11187596505934239
Epoch: 2
training loss: 0.002401664248994879
batch validation MSE: 0.2862121870965164 and MAE: 0.16624727950909654
Lowest batch validation MAE achieved, saving weights
R^2:  -0.1071963406647145
Epoch: 3
training loss: 0.0020410598398328903
batch validation MSE: 0.28470283079553377 and MAE: 0.1613811870600592
Lowest batch validation MAE achieved, saving weights
R^2:  -0.10135744585599471
Epoch: 4
training loss: 0.002379924495209445
batch validation MSE: 0.28297464959125856 and MAE: 0.1552953342487616
Lowest batch validation MAE achieved, saving weights
R^2:  -0.09467209259812992
Epoch: 5
training loss: 0.002076982302373057
batch validation MSE: 0.2809040054316723 and MAE: 0.14868729553177013
Lowest batch validation MAE achieved, saving weights
R^2:  -0.08666191101902654
Epoch: 6
training loss: 0.002058330038142902
batch validation MSE: 0.2786666891427826 and MAE: 0.15149330196751132
Epoch: 7
training loss: 0.0019325608245872154
batch validation MSE: 0.2762932210357924 and MAE: 0.15773218113358492
Epoch: 8
training loss: 0.0019748432746341635
batch validation MSE: 0.2740072523596003 and MAE: 0.16571795603109374
Epoch: 9
training loss: 0.002067428451400619
batch validation MSE: 0.2718391047238985 and MAE: 0.17466638629064635

Training and Validating CNN Wrapper
Epoch: 0
training loss: 0.000966367030785571
validation MSE: 0.0026839886414716865 and MAE: 0.002788471853569725
batch validation MSE: 0.055762250476143416 and MAE: 0.06555690334455387
Lowest batch validation MAE achieved, saving weights
R^2:  0.7842867535070167
Epoch: 1
training loss: 0.0004532955016181438
validation MSE: 0.0020067712012532663 and MAE: 0.0025100805116648967
batch validation MSE: 0.051418392313329654 and MAE: 0.06419730834193058
Lowest batch validation MAE achieved, saving weights
R^2:  0.801090733426217
Epoch: 2
training loss: 0.00028606514122232627
validation MSE: 0.0026919298642735946 and MAE: 0.0026949014115083825
batch validation MSE: 0.062330583799963396 and MAE: 0.0703688834433083
Epoch: 3
training loss: 0.0002268933858807821
validation MSE: 0.0018453815275674002 and MAE: 0.002318829604763258
batch validation MSE: 0.04579740294846832 and MAE: 0.05802533433244035
Lowest batch validation MAE achieved, saving weights
R^2:  0.8228352293048423
Epoch: 4
training loss: 0.00021862430982303534
validation MSE: 0.0018580180189024362 and MAE: 0.002295921076094325
batch validation MSE: 0.052214172213620555 and MAE: 0.06551410915615323
Epoch: 5
training loss: 0.00017496836161563661
validation MSE: 0.002115426091122686 and MAE: 0.002225333526510336
batch validation MSE: 0.05575119418495593 and MAE: 0.06528764140901265
Epoch: 6
training loss: 0.00016677725076109495
validation MSE: 0.0019230059618081956 and MAE: 0.002151122449729488
batch validation MSE: 0.04150368371049374 and MAE: 0.054686707838832796
Lowest batch validation MAE achieved, saving weights
R^2:  0.8394452498970679
Epoch: 7
training loss: 0.000117257860324179
validation MSE: 0.0016242955680860476 and MAE: 0.0019937139511256065
batch validation MSE: 0.05030874718454675 and MAE: 0.0627638096207971
Epoch: 8
training loss: 0.0002410084013639917
validation MSE: 0.0017093969210276382 and MAE: 0.0021747644444712554
batch validation MSE: 0.05105646902974276 and MAE: 0.06780469967975272
Epoch: 9
training loss: 9.05300485482543e-05
validation MSE: 0.0020731365716509698 and MAE: 0.002418901731800262
batch validation MSE: 0.05935852992889022 and MAE: 0.0700396492674544

Training and Validating ResNet50
Epoch: 0
training loss: 0.0007402539432601945
validation MSE: 0.0026901006328313767 and MAE: 0.0036649644097652653
batch validation MSE: 0.09264867477822511 and MAE: 0.13202017435787228
Lowest batch validation MAE achieved, saving weights
R^2:  0.6415936182009713
Epoch: 1
training loss: 0.00031298945500180843
validation MSE: 0.0025128752815453607 and MAE: 0.0034420099161223345
batch validation MSE: 0.07966534966165272 and MAE: 0.11852789838034827
Lowest batch validation MAE achieved, saving weights
R^2:  0.6918189127053782
Epoch: 2
training loss: 0.00019374208288019758
validation MSE: 0.0024686995757710038 and MAE: 0.003506278841962237
batch validation MSE: 0.06002639753217434 and MAE: 0.0876779309851495
Lowest batch validation MAE achieved, saving weights
R^2:  0.7677911326418102
Epoch: 3
training loss: 0.00011506708614669508
validation MSE: 0.0026061943882700026 and MAE: 0.0033198713593091686
batch validation MSE: 0.07597211439756106 and MAE: 0.11401835306304263
Epoch: 4
training loss: 0.00010373363629239236
validation MSE: 0.002108063296057408 and MAE: 0.0028968300483861787
batch validation MSE: 0.04963072133213177 and MAE: 0.08815669926168683
Epoch: 5
training loss: 8.985024165087574e-05
validation MSE: 0.0022874780472689235 and MAE: 0.003289524824598154
batch validation MSE: 0.084672552232615 and MAE: 0.11858333852813319
Epoch: 6
training loss: 6.846685014622187e-05
validation MSE: 0.0018561919268689562 and MAE: 0.0027937392143322793
batch validation MSE: 0.05530238018745074 and MAE: 0.0929960003458299
Epoch: 7
training loss: 6.763161957609833e-05
validation MSE: 0.002242054965407607 and MAE: 0.0029458626094423183
batch validation MSE: 0.04568858696407616 and MAE: 0.07927507206562671
Lowest batch validation MAE achieved, saving weights
R^2:  0.8232561757191804
Epoch: 8
training loss: 6.011494941033834e-05
validation MSE: 0.0017384221034625776 and MAE: 0.0028361140534033033
batch validation MSE: 0.0487554549693483 and MAE: 0.08335770977040131
Epoch: 9
training loss: 5.813069272480221e-05
validation MSE: 0.00228835393311825 and MAE: 0.002972486255345905
batch validation MSE: 0.048890296481447 and MAE: 0.08738265753732072

Training and Validating ResNet152
Epoch: 0
training loss: 0.0006634812524995617
validation MSE: 0.00259422583658357 and MAE: 0.0034928760894150663
batch validation MSE: 0.06272675564426552 and MAE: 0.11833704495802522
Lowest batch validation MAE achieved, saving weights
R^2:  0.7573449423531053
Epoch: 1
training loss: 0.00032739346886412416
validation MSE: 0.002280000520410905 and MAE: 0.0033324798828143734
batch validation MSE: 0.07099426161400228 and MAE: 0.10659590752812119
Lowest batch validation MAE achieved, saving weights
R^2:  0.7253625436191478
Epoch: 2
training loss: 0.00020745373104899623
validation MSE: 0.002384320673507202 and MAE: 0.0033726067837944284
batch validation MSE: 0.0841678516205332 and MAE: 0.1270291982638138
Epoch: 3
training loss: 0.00015805692173676513
validation MSE: 0.002453538349083034 and MAE: 0.0031488920874137207
batch validation MSE: 0.0794109801365128 and MAE: 0.10850053355685091
Epoch: 4
training loss: 0.00017038732900235713
validation MSE: 0.0019481490544953108 and MAE: 0.0029484890666900405
batch validation MSE: 0.057275338304578725 and MAE: 0.09579712892085449
Lowest batch validation MAE achieved, saving weights
R^2:  0.7784334578761232
Epoch: 5
training loss: 0.0001007546092197857
validation MSE: 0.0025692954361542374 and MAE: 0.0033436416906093523
batch validation MSE: 0.09994291196166843 and MAE: 0.11480120291329317
Epoch: 6
training loss: 7.097015026556982e-05
validation MSE: 0.0020220140389070273 and MAE: 0.0028608884320429867
batch validation MSE: 0.060731989554130984 and MAE: 0.09327521957121454
Lowest batch validation MAE achieved, saving weights
R^2:  0.7650615849056803
Epoch: 7
training loss: 4.89002284171032e-05
validation MSE: 0.0022359711902672024 and MAE: 0.0030347957879418874
batch validation MSE: 0.06569877795494403 and MAE: 0.10122756769058404
Epoch: 8
training loss: 5.097368204834156e-05
validation MSE: 0.0024754238837783617 and MAE: 0.0031211049592586152
batch validation MSE: 0.07479512133907584 and MAE: 0.10232117472149364
Epoch: 9
training loss: 4.680552947830529e-05
validation MSE: 0.0018704974651790026 and MAE: 0.0025470189067570074
batch validation MSE: 0.0478446331827005 and MAE: 0.08176109073515814
Lowest batch validation MAE achieved, saving weights
R^2:  0.8149156278453071

Training and Validating Vision Transformer Large 16
Epoch: 0
training loss: 0.001996871329949488
validation MSE: 0.004173990123716937 and MAE: 0.004031018877300914
batch validation MSE: 0.09999610757931021 and MAE: 0.12772328354552523
Lowest batch validation MAE achieved, saving weights
R^2:  0.613170485654408
Epoch: 1
training loss: 0.0006421411451899674
validation MSE: 0.003102619298092596 and MAE: 0.005265137789478223
batch validation MSE: 0.09186371117788325 and MAE: 0.21679278536959812
Epoch: 2
training loss: 0.0003757993345480885
validation MSE: 0.002915138229379835 and MAE: 0.0031799946656458403
batch validation MSE: 0.077407638988007 and MAE: 0.09644117182003217
Lowest batch validation MAE achieved, saving weights
R^2:  0.700552742510661
Epoch: 3
training loss: 0.00024085593072825664
validation MSE: 0.00247395533078411 and MAE: 0.003528769447964322
batch validation MSE: 0.07152603207526038 and MAE: 0.08288420941512864
Lowest batch validation MAE achieved, saving weights
R^2:  0.7233054224557478
Epoch: 4
training loss: 0.0002269257147355367
validation MSE: 0.002783309887982822 and MAE: 0.0032105235193800362
batch validation MSE: 0.08668111489357404 and MAE: 0.10729215092755653
Epoch: 5
training loss: 0.00012923757703335817
validation MSE: 0.0022955807942705376 and MAE: 0.0033949226508841893
batch validation MSE: 0.07851640986349971 and MAE: 0.13178966717945562
Epoch: 6
training loss: 0.00015601775686341623
validation MSE: 0.002584616705959518 and MAE: 0.003247041522068009
batch validation MSE: 0.0715351701086924 and MAE: 0.10881737819327428
Epoch: 7
training loss: 0.00014546455807541714
validation MSE: 0.0030847440392131266 and MAE: 0.003939812274983927
batch validation MSE: 0.08333593576219403 and MAE: 0.09045913880103612
Epoch: 8
training loss: 0.00015676914499302555
validation MSE: 0.0023275667362351307 and MAE: 0.002639545422430786
batch validation MSE: 0.06991599988769677 and MAE: 0.0773175551077804
Lowest batch validation MAE achieved, saving weights
R^2:  0.7295337428312065
Epoch: 9
training loss: 0.00011617086193134038
validation MSE: 0.0032801728552176264 and MAE: 0.0035206125388556626
batch validation MSE: 0.0841217962763105 and MAE: 0.11883892971384633

Training and Validating Faster R-CNN
Epoch: 0
training loss: 0.00724500738762268
validation MSE: 0.18859527184419406 and MAE: 0.07649513264607653
batch validation MSE: 1.5135135135135136 and MAE: 0.43243243243243246
Lowest batch validation MAE achieved, saving weights
R^2:  -4.854945054945054
Epoch: 1
training loss: 0.006121980722918732
validation MSE: 0.043810848949764634 and MAE: 0.03129346354738893
batch validation MSE: 0.13963963963963963 and MAE: 0.0945945945945946
Lowest batch validation MAE achieved, saving weights
R^2:  0.45981161695447426
Epoch: 2
training loss: 0.005325202178979219
validation MSE: 0.06453407520586327 and MAE: 0.041168289790150185
batch validation MSE: 0.5405405405405406 and MAE: 0.25225225225225223
Epoch: 3
training loss: 0.0049119358795918396
validation MSE: 0.07496522961803537 and MAE: 0.045201669979493375
batch validation MSE: 0.4954954954954955 and MAE: 0.24324324324324326
Epoch: 4
training loss: 0.004646771152187781
validation MSE: 0.05952712144282995 and MAE: 0.03671766399964172
batch validation MSE: 0.0990990990990991 and MAE: 0.08108108108108109
Lowest batch validation MAE achieved, saving weights
R^2:  0.6166405023547881
Epoch: 5
training loss: 0.004262042935370171
validation MSE: 0.051738525879399665 and MAE: 0.033936022696640956
batch validation MSE: 0.23873873873873874 and MAE: 0.13963963963963963
Epoch: 6
training loss: 0.00388329658764955
validation MSE: 0.050625869623477336 and MAE: 0.03310153027154474
batch validation MSE: 0.18018018018018017 and MAE: 0.12612612612612611
Epoch: 7
training loss: 0.0034893222880713714
validation MSE: 0.04200278189401136 and MAE: 0.029485396906132492
batch validation MSE: 0.1891891891891892 and MAE: 0.12612612612612611
Epoch: 8
training loss: 0.003435544571577796
validation MSE: 0.058553546843260154 and MAE: 0.037134910025666254
batch validation MSE: 0.4864864864864865 and MAE: 0.23423423423423423
Epoch: 9
training loss: 0.003048721458660161
validation MSE: 0.08595271234469222 and MAE: 0.04534075147004718
batch validation MSE: 0.7072072072072072 and MAE: 0.2927927927927928

Training and Validating SSD
Epoch: 0
training loss: 0.5981494971424379
validation MSE: 0.11585535507996324 and MAE: 0.05799721845623847
batch validation MSE: 0.27927927927927926 and MAE: 0.14414414414414414
Lowest batch validation MAE achieved, saving weights
R^2:  -0.08037676609105149
Epoch: 1
training loss: 0.5289732059607555
validation MSE: 0.11599443715081262 and MAE: 0.058136300527087834
batch validation MSE: 0.2702702702702703 and MAE: 0.14414414414414414
Epoch: 2
training loss: 0.48243279884679063
validation MSE: 0.11571627302983871 and MAE: 0.05785813640611394
batch validation MSE: 0.2747747747747748 and MAE: 0.13963963963963963
Lowest batch validation MAE achieved, saving weights
R^2:  -0.06295133437990552
Epoch: 3
training loss: 0.4440143031549445
validation MSE: 0.11237830358851436 and MAE: 0.05479833123083738
batch validation MSE: 0.21171171171171171 and MAE: 0.11261261261261261
Lowest batch validation MAE achieved, saving weights
R^2:  0.18100470957613835
Epoch: 4
training loss: 0.42814534280451183
validation MSE: 0.10917941611441519 and MAE: 0.05438108498720201
batch validation MSE: 0.20270270270270271 and MAE: 0.11261261261261261
Epoch: 5
training loss: 0.37582829464237105
validation MSE: 0.1027816415599888 and MAE: 0.05187760814713503
batch validation MSE: 0.13963963963963963 and MAE: 0.1036036036036036
Lowest batch validation MAE achieved, saving weights
R^2:  0.45981161695447426
Epoch: 6
training loss: 0.3585233492954259
validation MSE: 0.10347705210075922 and MAE: 0.052851182394382516
batch validation MSE: 0.15315315315315314 and MAE: 0.11711711711711711
Epoch: 7
training loss: 0.3425037900469744
validation MSE: 0.10709318473043959 and MAE: 0.056189151960055916
batch validation MSE: 0.27927927927927926 and MAE: 0.21621621621621623
Epoch: 8
training loss: 0.31796161530995504
validation MSE: 0.08581362981789632 and MAE: 0.04492350509170034
batch validation MSE: 0.14414414414414414 and MAE: 0.11711711711711711
Epoch: 9
training loss: 0.28142717410873686
validation MSE: 0.06954102961136668 and MAE: 0.04089012566917629
batch validation MSE: 0.18018018018018017 and MAE: 0.16216216216216217

Training and Validating RetinaNet
Epoch: 0
training loss: 0.03162025010414663
validation MSE: 0.1112656471149812 and MAE: 0.05507649534144886
batch validation MSE: 0.17567567567567569 and MAE: 0.1036036036036036
Lowest batch validation MAE achieved, saving weights
R^2:  0.3204081632653063
Epoch: 1
training loss: 0.01919614171246252
validation MSE: 0.09666203055660316 and MAE: 0.04770514615636542
batch validation MSE: 0.15765765765765766 and MAE: 0.08558558558558559
Lowest batch validation MAE achieved, saving weights
R^2:  0.3901098901098903
Epoch: 2
training loss: 0.018251684967817615
validation MSE: 0.08942976347345637 and MAE: 0.046036161699944976
batch validation MSE: 0.11711711711711711 and MAE: 0.06306306306306306
Lowest batch validation MAE achieved, saving weights
R^2:  0.5469387755102042
Epoch: 3
training loss: 0.013940620253237517
validation MSE: 0.06759388090962329 and MAE: 0.0358831713258474
batch validation MSE: 0.08108108108108109 and MAE: 0.06306306306306306
Epoch: 4
training loss: 0.011429194782866959
validation MSE: 0.05326842895925294 and MAE: 0.029346314824920703
batch validation MSE: 0.05855855855855856 and MAE: 0.04954954954954955
Lowest batch validation MAE achieved, saving weights
R^2:  0.7734693877551021
Epoch: 5
training loss: 0.011781869322109948
validation MSE: 0.0680111273190574 and MAE: 0.039638386917545336
batch validation MSE: 0.1036036036036036 and MAE: 0.06756756756756757
Epoch: 6
training loss: 0.011639705864295111
validation MSE: 0.05243393626473378 and MAE: 0.029624478759371024
batch validation MSE: 0.11711711711711711 and MAE: 0.06306306306306306
Epoch: 7
training loss: 0.009716925436726772
validation MSE: 0.04394993080300316 and MAE: 0.0269819198588171
batch validation MSE: 0.08558558558558559 and MAE: 0.06756756756756757
Epoch: 8
training loss: 0.007971184058533821
validation MSE: 0.04019471525275492 and MAE: 0.02461752456111603
batch validation MSE: 0.04954954954954955 and MAE: 0.04054054054054054
Lowest batch validation MAE achieved, saving weights
R^2:  0.808320251177394
Epoch: 9
training loss: 0.00771821027300607
validation MSE: 0.030319888927094297 and MAE: 0.021418637242453156
batch validation MSE: 0.12162162162162163 and MAE: 0.08558558558558559
